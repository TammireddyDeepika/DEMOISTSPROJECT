{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMnqCTkW+r0DPbVAKjkSWx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TammireddyDeepika/DEMOISTSPROJECT/blob/main/GEN_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ypgbcv4Amm95",
        "outputId": "8ff82d8b-3211-4245-974b-dc43b1a88099"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n"
          ]
        }
      ],
      "source": [
        "pip install transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "\n",
        "#Load pretrained Generative AI model\n",
        "text_generator = pipeline('text-generation', model='gpt2')\n",
        "\n",
        "#Take user input\n",
        "topic = input(\"Enter a topic:\")\n",
        "\n",
        "#Create prompt\n",
        "prompt = f\"write 5 lines about {topic} in simple words.\"\n",
        "\n",
        "#Generate AI Text\n",
        "result = text_generator(prompt,max_length=120,num_return_sequences=1)\n",
        "\n",
        "#Output\n",
        "print(\"\\n---Generated Text----\\n\")\n",
        "print(result[0][\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xUsw-j2ms3-",
        "outputId": "2e6c8375-38fe-4db8-9e32-76f5aa3452b2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a topic:tree\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=120) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---Generated Text----\n",
            "\n",
            "write 5 lines about tree in simple words. I want to look for \"Tree 1\" and \"Tree 2\", but they aren't \"tree 1\".\n",
            "\n",
            "The first thing I do is make a tree with the \"tree 1 tree 2\" name.\n",
            "\n",
            "#!/usr/bin/env python print(tree_name(tree_name, 1)) # This will print that we have \"Tree 1 tree 2 tree\" print(tree_name(tree_name, 2))\n",
            "\n",
            "I make the following tree:\n",
            "\n",
            "#!/usr/bin/env python print(tree_name(tree_name, 1)) # This will print that we have \"Tree 1 tree 2 tree\" print(tree_name(tree_name, 2)) # This will print that we have \"Tree 1 tree 2 tree\" print(tree_name(tree_name, 2))\n",
            "\n",
            "This will generate the following output:\n",
            "\n",
            "Tree 1 tree 2 tree 1 tree 2 tree 3 tree 3 tree\n",
            "\n",
            "Now I turn the tree to the \"tree 1 tree 2\" name.\n",
            "\n",
            "#!/usr/bin/env python print(tree_name(tree_name, 1)) # This will print that we have \"Tree 1 tree 2 tree\" print(tree_name(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "#load text generation model\n",
        "generator = pipeline(\"text-generation\",model=\"gpt2\",pad_token_id=50256)\n",
        "\n",
        "#User input\n",
        "topic = input(\"Enter a topic: \")\n",
        "\n",
        "#Strict Prompt\n",
        "prompt = (f\"write exactly 5 simple lines about {topic}.\\n\"\n",
        "\"1.\"\n",
        ")\n",
        "\n",
        "#Genetare text\n",
        "output = generator(prompt,max_new_tokens=80,do_sample=True,temperature=0.7,top_k=50)\n",
        "\n",
        "#Print result\n",
        "print(\"\\n---Generated Text---\\n\")\n",
        "print(output[0][\"generated_text\"])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHJtjepLpBcd",
        "outputId": "15b840ea-fa19-43ae-e1a5-b24a61def83d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a topic: tree\n",
            "\n",
            "---Generated Text---\n",
            "\n",
            "write exactly 5 simple lines about tree.\n",
            "1. Create a new tree using the program below.\n",
            "2. Go to root, and press Enter.\n",
            "3. When the program runs, you should see a new tree.\n",
            "4. Go to root again.\n",
            "5. When the program runs, you should see a new tree.\n",
            "6. Go to root again.\n",
            "7. When the program runs, you should see a new tree\n"
          ]
        }
      ]
    }
  ]
}